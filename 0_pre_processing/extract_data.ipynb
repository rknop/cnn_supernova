{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to extract data from .gif files into .npy arrays\n",
    "### Feb 27, 2020 \n",
    "##### Venkitesh Ayyar (vpa@lbl.gov)\n",
    "Two modes: full will extract the entire dataset. split will extract the 3 types of files: srch,temp,diff into separate .npy files\n",
    "\n",
    "Feb 27: Modified to combine the 3 types of files into a 3channel image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def f_get_df():\n",
    "    '''\n",
    "    Function to get Dataframe and shuffle entires\n",
    "    3 modes: \n",
    "    - full: Get a big dataframe, shuffling all entries\n",
    "    - split: Split dataframe into :srch,temp,diff and shuffle each and return list of 3 dataframes\n",
    "    '''\n",
    "    \n",
    "    data_dir='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/'\n",
    "    fname1=data_dir+'summary_label_files.csv'\n",
    "    df=pd.read_csv(fname1,sep=',',comment='#')\n",
    "    \n",
    "    ### Print summary of data\n",
    "    print(df.shape)\n",
    "    num_samples=df.shape[0]\n",
    "    num_sig,num_bkgnd=df[df.Label==1].shape[0],df[df.Label==0].shape[0]\n",
    "    print(\"Proportion of Signal-Background: {0}-{1}\\nProportion of Signal: {2}\".format(num_sig,num_bkgnd,num_sig*1.0/(num_sig+num_bkgnd)))\n",
    "\n",
    "#     df=df.head(300)  ## When using parts, make sure you take multiples of 3 so that all 3 files for each ID are taken\n",
    "#     df=df.sample(frac=1.0,random_state=37)  ### The shuffling part is done in the np array of IDs rather than here. \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def f_get_data(df):\n",
    "    '''\n",
    "    Function to get data from .gif files into index, images, labels.\n",
    "    Uses matplotlib.pyplot.imread \n",
    "    '''\n",
    "    \n",
    "    combined_imgs_lst=[]\n",
    "    label_lst=[]\n",
    "    ### Get list of IDs. Each ID has a srch,temp,diff file\n",
    "    idx_arr=np.unique(df.ID.values)\n",
    "    \n",
    "    ## Shuffle IDs\n",
    "    np.random.seed(37)\n",
    "    np.random.shuffle(idx_arr) ## When using parts, make sure you take multiples of 3 so that all 3 files for each ID are taken\n",
    "\n",
    "    ### Iterate over IDs, stacking 3 numpy arrays (temp,srch,diff) for each\n",
    "    for idx in idx_arr:\n",
    "        try: \n",
    "            ### Extract the 3 images and create stacked numpy array\n",
    "            file_list=[df[(df.ID==idx) & (df.filename.str.startswith(strg))]['file path'].values[0] for strg in ['temp','srch','diff']]\n",
    "            \n",
    "            img=np.dstack([plt.imread(fle) for fle in file_list]) ## Create stacked numpy array of 3 images\n",
    "        #     img=np.expand_dims(img,axis=0)\n",
    "            combined_imgs_lst.append(img)             ## Append image to list\n",
    "\n",
    "            ### Extract the first label\n",
    "            label=[df[(df.ID==idx) & (df.filename.str.startswith(strg))]['Label'].values[0] for strg in ['temp','srch','diff']]\n",
    "            ## Check that all 3 images have same label\n",
    "            assert all(x==label[0] for x in label), \"Labels for temp,srch,diff are not identical %\"%(label)\n",
    "            label_lst.append(label[0])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e,'for index',idx)\n",
    "            pass\n",
    "    \n",
    "    ### Stack the combined image list\n",
    "    images=np.stack(combined_imgs_lst,axis=0)\n",
    "    print(images.shape)\n",
    "    \n",
    "    ### Extract labels\n",
    "    labels = np.array(label_lst)\n",
    "    \n",
    "    ### Store the ID of the dataframe\n",
    "    idx=idx_arr[:]\n",
    "    \n",
    "    return idx,images,labels \n",
    "\n",
    "\n",
    "def f_save_files(idx,img,label,name_prefix):\n",
    "    '''\n",
    "    Save the ID, image and label in 3 .npy files\n",
    "    '''\n",
    "    save_location='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/temp_data/'\n",
    "    f1,f2,f3=[name_prefix+i for i in ['idx','x','y']]\n",
    "    \n",
    "    for fname,data in zip([f1,f2,f3],[idx,img,label]):\n",
    "        np.save(save_location+fname,data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    t1=time.time()\n",
    "    df=f_get_df()\n",
    "    t2=time.time()\n",
    "#     df=df.head(300)\n",
    "    print(\"Setup time\",t2-t1)\n",
    "    idx,img,label=f_get_data(df)\n",
    "    t3=time.time()\n",
    "    print(\"Extraction time\",t3-t2)\n",
    "    f_save_files(idx,img,label,name_prefix='full_')\n",
    "    t4=time.time()\n",
    "    \n",
    "    print(\"File save time %s\"%(t4-t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check by reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/temp_data/full_x.npy'\n",
    "fname='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/full_x.npy'\n",
    "\n",
    "# fname='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/temp_data/temp_x.npy'\n",
    "\n",
    "a1=np.load(fname)\n",
    "# a2=np.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/temp_data/full_x.npy'\n",
    "# a3=np.load(fname)\n",
    "\n",
    "# fname='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/temp_data/full_idx.npy'\n",
    "# a4=np.load(fname)\n",
    "\n",
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 51, 51, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- Add a check function to ensure stacked arrays are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66667.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200001/3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
