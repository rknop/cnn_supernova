{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to normalize the images\n",
    "April 7, 2020\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import subprocess as sp\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook modules_image_analysis.ipynb to script\n",
      "[NbConvertApp] Writing 8876 bytes to modules_image_analysis.py\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/global/u1/v/vpa/project/jpt_notebooks/Cosmology/Cosmo_GAN/LBANN/lbann_cosmogan/3_analysis/')\n",
    "from modules_image_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname1=data_dir+'summary_label_files.csv'\n",
    "df1=pd.read_csv(fname1,sep=',',comment='#')\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sig,num_bkgnd=df1[df1.Label==1].shape[0],df1[df1.Label==0].shape[0]\n",
    "print(\"Proportion of Signal-Background: {0}-{1}.\\nProportion of Signal: {2}\".format(num_sig,num_bkgnd,num_sig*1.0/(num_sig+num_bkgnd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a slice of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extracting 30 images of signal and bkgnd\n",
    "size= 3000\n",
    "df_sig=df1[df1.Label==1].head(size)\n",
    "df_bkg=df1[df1.Label==0].head(size)\n",
    "\n",
    "del(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sig\n",
    "# df_bkg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_get_image_arr(df,mode='type',ftype='diff',idx=5):\n",
    "    '''\n",
    "    Module to get image arrays from dataframe with filenames\n",
    "    Input: Dataframe, mode\n",
    "    2 modes: \n",
    "    'type': Gives all the images for the same type of files,\n",
    "    'index': Gives all 3 types for the same index\n",
    "    'ftype': type of files to extract : srch, temp, diff\n",
    "    'idx': index number of ID array from which to extract\n",
    "    '''\n",
    "    \n",
    "    if mode=='type': ### Pick all images of type=ftype\n",
    "        df2=df[df.filename.str.contains(ftype)].reset_index(drop=True)\n",
    "        ### Read .gif files and store them in an array\n",
    "        imgs=[plt.imread(fle) for fle in df2['file path']]\n",
    "        \n",
    "    elif mode=='index': ### Pick srch','temp','diff'\n",
    "        index=np.unique(df_sig.ID.values)[idx]\n",
    "        df2=df[df.ID==index].reset_index(drop=True)\n",
    "        imgs=[plt.imread(fle) for fle in df2['file path']]\n",
    "    \n",
    "    df2.loc[:,'image']=imgs\n",
    "    return df2\n",
    "\n",
    "\n",
    "# df=f_get_image_arr(df_sig,mode='index',idx=0)\n",
    "# df=f_get_image_arr(df_sig,mode='type',ftype='diff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=f_get_image_arr(df_sig,mode='type',ftype='temp')\n",
    "img_arr=np.stack(df.image.values)\n",
    "f_pixel_intensity(img_arr,normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_compare_pixel_intensity_images(df_input,title,mode='normal'):\n",
    "    '''\n",
    "    Compare pixel intensity histogram of all 3 files.\n",
    "    2 modes: \n",
    "        normal: takes all values and computes histogram\n",
    "        averaged: takes histograms for each images and computes mean and error\n",
    "    '''\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    for ftype in['srch','temp','diff']:\n",
    "        df=f_get_image_arr(df_input,mode='type',ftype=ftype)\n",
    "        img_arr=np.stack(df.image.values)  ### Extract the image array samples\n",
    "        \n",
    "        norm=True\n",
    "        if mode=='normal':\n",
    "            hist, bin_edges = np.histogram(img_arr.flatten(), bins=25, density=norm)\n",
    "            centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "            #     print(bin_edges,centers)\n",
    "            plt.errorbar(centers, hist, fmt='o-', label=ftype)\n",
    "\n",
    "        elif mode=='avg':\n",
    "            hist_arr=np.array([np.histogram(arr.flatten(), bins=25, density=norm) for arr in img_arr])\n",
    "            hist=np.stack(hist_arr[:,0])\n",
    "            bins=np.stack(hist_arr[:,1])\n",
    "            ### Compute statistics of histogram of each image\n",
    "            mean,err=np.mean(hist,axis=0),np.std(hist,axis=0)/np.sqrt(hist.shape[0])\n",
    "            bin_edges=bins[0]\n",
    "            centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "            plt.errorbar(centers,mean,yerr=err,fmt='o-',label=ftype)\n",
    "        \n",
    "        \n",
    "    plt.xlabel('Pixel value')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Pixel Intensity Histogram of '+title)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    \n",
    "f_compare_pixel_intensity_images(df_sig,'signal',mode='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_compare_pixel_intensity_images(df_bkg,title='bkgnd',mode='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_compute_spectrum(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=f_get_image_arr(df_sig,mode='index',idx=0)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=df.image.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing MAD: Median Absolute Deviation\n",
    "https://en.wikipedia.org/wiki/Median_absolute_deviation\n",
    "\n",
    "$ MAD=Median \\left(X-\\tilde{X} \\right) \\ \\ $   where $ \\tilde{X}$ is the median of array\n",
    "\n",
    "$ \\sigma = k . MAD $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_mad(arr):\n",
    "    '''\n",
    "    Compute MAD and std\n",
    "    '''\n",
    "    arr2=arr.flatten()\n",
    "    MD=np.median(arr2)\n",
    "#     print(MD)\n",
    "    mad=np.median(np.abs(arr2-MD))\n",
    "    k=1.4826 ### For normal distribution\n",
    "    sigma=mad*k\n",
    "\n",
    "    return mad,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=img_arr[:10]\n",
    "f_mad(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2=arr.flatten()\n",
    "MD=np.median(arr2)\n",
    "print(MD)\n",
    "arr3=np.abs(arr2-MD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement normalization with actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.load('/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/input_npy_files/full_x.npy')\n",
    "samples=arr[:]\n",
    "# del arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_mad(arr):\n",
    "    '''\n",
    "    Compute MAD and std\n",
    "    '''\n",
    "#     print(arr.shape)\n",
    "    arr2=arr.flatten()\n",
    "    MD=np.median(arr2)\n",
    "#     print(MD)\n",
    "    mad=np.median(np.abs(arr2-MD))\n",
    "    k=1.4826 ### For normal distribution\n",
    "    sigma=mad*k\n",
    "\n",
    "    return mad,sigma\n",
    "\n",
    "def f_vectorize(arr):\n",
    "    return np.vectorize(f_mad)(arr)\n",
    "\n",
    "\n",
    "\n",
    "# print(samples.shape)\n",
    "# t1=time.time()\n",
    "# scaled_samples=np.array([(1.0/f_mad(i[:,:,2])[1])*i for i in samples])\n",
    "scales_arr=np.array([(1.0/f_mad(i[:,:,2])[1]) for i in samples])\n",
    "\n",
    "# t2=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_scale(arr):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    samples=arr[:]\n",
    "    s2=samples[:,:,:,2].reshape(N,51*51)\n",
    "    scales=np.apply_along_axis(f_mad,1,s2)\n",
    "#     print(scales.shape,samples.shape)\n",
    "    scaled_arr=np.einsum('i,ijkl->ijkl',(1.0/scales),samples)\n",
    "    \n",
    "    return scaled_arr\n",
    "\n",
    "def f_rescale_samples(samples):\n",
    "    ''' Rescale individual images with MAD value of diff image\n",
    "    '''\n",
    "    def f_mad(arr):\n",
    "        '''\n",
    "        Compute MAD and std\n",
    "        '''\n",
    "        arr2=arr.flatten()\n",
    "        MD=np.median(arr2)\n",
    "    #     print(MD)\n",
    "        mad=np.median(np.abs(arr2-MD))\n",
    "        k=1.4826 ### For normal distribution\n",
    "        sigma=mad*k\n",
    "\n",
    "        return mad,sigma\n",
    "\n",
    "    scaled_samples=np.array([(1.0/f_mad(i[:,:,2])[1]+1e-6)*i for i in samples])\n",
    "\n",
    "#     scales=np.apply\n",
    "#     scaled_2=np.einsum('i,ijkl->ijkl',,samples)\n",
    "    return scaled_samples\n",
    "\n",
    "\n",
    "# f_scale(arr[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedure for normalization : \n",
    "\n",
    "For each sample (3 image types)\n",
    "- Computed sigma using MAD method on diff image\n",
    "- Divide entire sample by that value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898963, 51, 51, 3)\n",
      "Small value 1808 0.0\n",
      "1808 (51, 51, 3) (35.0, 51.891) (36.0, 53.373599999999996) (0.0, 0.0)\n",
      "Small value 1856 0.0\n",
      "1856 (51, 51, 3) (5.0, 7.412999999999999) (13.0, 19.273799999999998) (0.0, 0.0)\n",
      "Small value 3176 0.0\n",
      "3176 (51, 51, 3) (1.0, 1.4826) (2.0, 2.9652) (0.0, 0.0)\n",
      "Small value 5066 0.0\n",
      "5066 (51, 51, 3) (50.0, 74.13) (54.0, 80.0604) (0.0, 0.0)\n",
      "1.8579940795898438\n",
      "(10000, 51, 51, 3)\n"
     ]
    }
   ],
   "source": [
    "save_location='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/input_npy_files/'\n",
    "f1='full_x.npy'\n",
    "f2='renorm_full_x.npy'\n",
    "\n",
    "ip_arr=np.load(save_location+f1)\n",
    "print(ip_arr.shape)\n",
    "\n",
    "def f_rescale_samples(samples):\n",
    "    ''' Rescale individual images with MAD value of diff image\n",
    "    '''\n",
    "    def f_mad(arr):\n",
    "        '''\n",
    "        Compute MAD and std\n",
    "        '''\n",
    "        arr2=arr.flatten()\n",
    "        MD=np.median(arr2)\n",
    "    #     print(MD)\n",
    "        mad=np.median(np.abs(arr2-MD))\n",
    "        k=1.4826 ### For normal distribution\n",
    "        sigma=mad*k\n",
    "\n",
    "        return mad,sigma\n",
    "    \n",
    "    \n",
    "    scaled_samples=np.ones_like(samples)\n",
    "    lst_zeros=[] # List to store indices where the MAD value is zero\n",
    "    for i,row in enumerate(samples):\n",
    "        scale=f_mad(row[:,:,2])[1]\n",
    "        if scale<1e-10: \n",
    "            print(\"Small value\",i,scale)\n",
    "            print(i,row.shape,f_mad(row[:,:,0]),f_mad(row[:,:,1]),f_mad(row[:,:,2]))\n",
    "            lst_zeros.append(i)\n",
    "            scale=1.0\n",
    "        scaled_samples[i]=row*(1.0/scale)\n",
    "        \n",
    "        \n",
    "    ### For every row, compute the MAD value for diff image (idx =2 ) and multiple its inverse to each sample\n",
    "#     scaled_samples=np.array([(1.0/f_mad(i[:,:,2])[1]+1e-6)*i for i in samples])\n",
    "    \n",
    "    return scaled_samples,lst_zeros\n",
    "\n",
    "t1=time.time()\n",
    "rescaled_arr,zero_lst=f_rescale_samples(ip_arr[:10000])\n",
    "t2=time.time()\n",
    "print(t2-t1)\n",
    "\n",
    "print(rescaled_arr.shape)\n",
    "# np.save(save_location+f2,rescaled_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d510d75c66644e26bdd104ad28e8ff43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b567f04ed474e4e9efc6cac197d22af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f30a649adfb418295781e31992d5575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098a3198211941bca98ad65aa5b2ee28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in zero_lst:\n",
    "    img=ip_arr[idx][:,:,2]\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 51, 51, 3)\n"
     ]
    }
   ],
   "source": [
    "# a2=np.load(save_location+f2)\n",
    "# print(a2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_mad(arr):\n",
    "    '''\n",
    "    Compute MAD and std\n",
    "    '''\n",
    "    arr2=arr.flatten()\n",
    "    MD=np.median(arr2)\n",
    "#     print(MD)\n",
    "    mad=np.median(np.abs(arr2-MD))\n",
    "    k=1.4826 ### For normal distribution\n",
    "    sigma=mad*k\n",
    "\n",
    "    return mad,sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_mad(ip_arr[1808,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1808, 1856, 3176, 5066]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
