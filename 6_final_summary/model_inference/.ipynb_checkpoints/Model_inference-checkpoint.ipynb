{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model\n",
    "Read stored model and test on custom dataset\\\n",
    "Sep 1, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "## M-L modules\n",
    "# import tensorflow.keras\n",
    "# import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"Parse command line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Train and test CNN for Supernova data\")\n",
    "    add_arg = parser.add_argument\n",
    "    \n",
    "    add_arg('--model','-m', type=str, default='models/model_1.h5',help='The name of stored model file.')\n",
    "    add_arg('--input','-i', type=str, default='data/',help='The name of input image file. Format: (n_samples, 51, 51, 3)')\n",
    "    add_arg('--output','-o', type=str, default='results/',help='Folder to place the inference results')\n",
    "\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model file /global/cfs/cdirs/dasrepo/vpa/supernova_cnn/data/results_data/results/final_summary_data_folder/saved_models/model_1.h5\n",
      "Reading input data from /global/cfs/cdirs/dasrepo/vpa/supernova_cnn/data/results_data/results/final_summary_data_folder/sample_test_data/input_x.npy\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "Results saved in /global/cfs/cdirs/dasrepo/vpa/supernova_cnn/data/results_data/results/final_summary_data_folder/results_inference/y_pred.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    main_dir='/global/cfs/cdirs/dasrepo/vpa/supernova_cnn/data/results_data/results/final_summary_data_folder/'\n",
    "    stored_model=main_dir+'saved_models/'+'model_1.h5'\n",
    "    ip_file=main_dir+'sample_test_data/input_x.npy'\n",
    "    results_dir=main_dir+'results_inference/'\n",
    "    \n",
    "#     args=parse_args()\n",
    "#     print(args)\n",
    "#     ip_file=args.input\n",
    "#     stored_model=args.model\n",
    "#     results_dir=args.output\n",
    "    \n",
    "    print(\"Reading model file\",stored_model)\n",
    "    print(\"Reading input data from\",ip_file)\n",
    "    \n",
    "    ## Store data in numpy array\n",
    "    ip_images=np.load(ip_file)\n",
    "    \n",
    "    ## Check if file exist\n",
    "    assert os.path.exists(stored_model),\"Model not saved: %s\"%(stored_model)\n",
    "    ## Load model from file\n",
    "    Model=load_model(stored_model)\n",
    "    \n",
    "    #################################\n",
    "    ### Model Inference ###\n",
    "    y_pred=Model.predict(ip_images,verbose=1)\n",
    "    \n",
    "    ## Save prediction array\n",
    "    op_file=results_dir+'y_pred.txt'\n",
    "    np.savetxt(op_file,y_pred)\n",
    "\n",
    "    print(\"Results saved in %s\"%(op_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3",
   "language": "python",
   "name": "v-jpt-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
