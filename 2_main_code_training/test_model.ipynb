{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model\n",
    "Read stored model and test on custom dataset\\\n",
    "Sep 1, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "import subprocess as sp\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "## M-L modules\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks  # or tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "## modules from other files\n",
    "from models import *\n",
    "from utils import dataset, cnn_model, f_get_data, f_load_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir='/global/cfs/cdirs/dasrepo/vpa/supernova_cnn/data/results_data/results/test_with_new_labels/'\n",
    "data_dir='/global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/input_npy_files/'\n",
    "prefix='full'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file name /global/project/projectdirs/dasrepo/vpa/supernova_cnn/data/gathered_data/input_npy_files/full_x.npy\n",
      "Size of entire dataset is :  898963\n",
      "Shapes of indices (449481,) (44948,) (44948,)\n",
      "Time taken to read and process input files 18.613744258880615\n"
     ]
    }
   ],
   "source": [
    "## Create dataset using indices\n",
    "\n",
    "#### Read data from files \n",
    "data_dict=f_get_data(prefix,data_dir,pre_norm=False)\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "size_data=data_dict['labels'].shape[0]\n",
    "print(\"Size of entire dataset is : \",size_data)\n",
    "#### Define the indices for training, validation and test data\n",
    "train_size,val_size,test_size=int(0.5*size_data),int(0.05*size_data),int(0.05*size_data)\n",
    "# train_size,val_size,test_size=int(0.0*size_data),int(0.0*size_data),int(1.0*size_data)\n",
    "\n",
    "\n",
    "### Get random indices for test,train,val\n",
    "np.random.seed(225) # Set random seed\n",
    "test_idx=np.random.choice(np.arange(size_data),test_size,replace=False)\n",
    "# get remaining indices without test indices\n",
    "rem_idx1=np.array(list(set(np.arange(size_data))-set(test_idx)))\n",
    "val_idx=np.random.choice(rem_idx1,val_size,replace=False)\n",
    "rem_idx2=np.array(list(set(rem_idx1)-set(val_idx)))\n",
    "train_idx=np.random.choice(rem_idx2,train_size,replace=False)\n",
    "\n",
    "print(\"Shapes of indices\",train_idx.shape, val_idx.shape, test_idx.shape)\n",
    "\n",
    "#### Storing arrays into train,validation, test objects and deleting the full data dictionary\n",
    "train_data=dataset('training',data_dict,train_idx)\n",
    "val_data=dataset('validation',data_dict,val_idx)\n",
    "test_data=dataset('test',data_dict,test_idx)\n",
    "del data_dict\n",
    "# print(\"\\nData shapes: Train {0}, Validation {1}, Test {2}\\n\".format(train_data.x.shape,val_data.x.shape,test_data.x.shape))\n",
    "\n",
    "t2=time.time()\n",
    "print(\"Time taken to read and process input files\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking that order of stored ids is same as that in the dictionary\n",
    "test_ids=np.loadtxt(model_save_dir+'id_test_3.test')\n",
    "np.array_equal(test_ids,test_data.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relabel target (y)\n",
    "new_test_y=np.loadtxt(model_save_dir+'ytest_3.test') \n",
    "test_data.y=new_test_y ### Relabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1103 06:49:01.206565 46912496688512 deprecation.py:506] From /global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1103 06:49:01.223641 46912496688512 deprecation.py:506] From /global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1103 06:49:01.241270 46912496688512 deprecation.py:506] From /global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1103 06:49:01.408630 46912496688512 deprecation.py:506] From /global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W1103 06:49:06.171962 46912496688512 deprecation.py:323] From /global/homes/v/vpa/.conda/envs/v_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44948, 51, 51, 3)\n",
      "44948/44948 [==============================] - 5s 108us/sample\n",
      "8\n",
      "(44948, 51, 51, 3)\n",
      "44948/44948 [==============================] - 5s 111us/sample\n",
      "9\n",
      "(44948, 51, 51, 3)\n",
      "44948/44948 [==============================] - 7s 152us/sample\n",
      "16\n",
      "(44948, 51, 51, 3)\n",
      "44948/44948 [==============================] - 3s 62us/sample\n"
     ]
    }
   ],
   "source": [
    "# model_name='3'\n",
    "for model_name in [str(i) for i in [3,8,9,16]]:\n",
    "    print(model_name)\n",
    "    ### Define Object for cnn_model\n",
    "    Model=cnn_model(model_name,model_save_dir)\n",
    "\n",
    "    ### Read stored model and history\n",
    "    Model.f_load_model_history()\n",
    "\n",
    "    #################################\n",
    "    ### Test model ###\n",
    "    Model.f_test_model(data)\n",
    "\n",
    "    ## Save prediction array and labels array\n",
    "    Model.f_save_predictions(data,val_data,val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_py3",
   "language": "python",
   "name": "v_jpt_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
